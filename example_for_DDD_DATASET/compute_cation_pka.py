import pandas as pd
import os
import subprocess
import re
from pathlib import Path
import multiprocessing as mp
from functools import partial

def find_pdb_files(directory, pdb_pattern="*_only_protein.pdb"):

    return [f for f in os.listdir(directory) if f.endswith(pdb_pattern.replace("*", ""))]

def run_propka_and_extract_pka(args):
 
    directory, pdb_file, residue_info, pdb_pattern = args
    
    # Extract residue name, number, and chain from residue_info
    match = re.match(r'([A-Z]+)-(\d+)-([A-Z])', residue_info)
    if not match:
        print(f"Invalid residue format: {residue_info}")
        return directory, residue_info, None
    
    res_name = match.group(1)
    res_num = int(match.group(2))
    chain_id = match.group(3)
    
    # Create the .pka filename based on the PDB filename
    pka_filename = pdb_file.replace('.pdb', '.pka')
    
    # Change to the directory
    original_dir = os.getcwd()
    try:
        os.chdir(directory)
    except FileNotFoundError:
        print(f"Directory {directory} not found")
        return directory, residue_info, None
    
    # Check if .pka file already exists
    if os.path.exists(pka_filename):
        print(f"Using existing .pka file: {pka_filename}")
    else:
        # Run propka3 to generate the .pka file
        try:
            result = subprocess.run(['propka3', pdb_file], 
                                  capture_output=True, text=True, check=True)
            print(f"Propka3 completed for {pdb_file}")
        except subprocess.CalledProcessError as e:
            print(f"Error running propka3 on {pdb_file}: {e}")
            print(f"stdout: {e.stdout}")
            print(f"stderr: {e.stderr}")
            os.chdir(original_dir)
            return directory, residue_info, None
        except FileNotFoundError:
            print("propka3 command not found. Please make sure propka3 is installed and in PATH.")
            os.chdir(original_dir)
            return directory, residue_info, None

    # Extract pKa from the .pka file (either existing or newly created)
    pka_value = extract_pka_from_propka_file(pka_filename, residue_info)
    
    # Return to original directory
    os.chdir(original_dir)
    
    return directory, residue_info, pka_value

def extract_pka_from_propka_file(propka_file, residue_info):
    """
    Extract pKa from a propka-generated .pka file.
    
    Args:
        propka_file: Path to the .pka file generated by propka
        residue_info: String in format like "ARG-264-A"
    
    Returns:
        pKa value as float, or None if not found
    """
    # Extract residue name, number, and chain from residue_info
    match = re.match(r'([A-Z]+)-(\d+)-([A-Z])', residue_info)
    if not match:
        print(f"Invalid residue format: {residue_info}")
        return None
    
    res_name = match.group(1)
    res_num = int(match.group(2))
    chain_id = match.group(3)
    
    try:
        with open(propka_file, 'r') as file:
            lines = file.readlines()
            
            # Look for the summary section which typically contains the pKa values
            in_summary = False
            for line in lines:
                if line.startswith('SUMMARY OF THIS PREDICTION'):
                    in_summary = True
                    continue
                
                if in_summary and line.strip() and not line.startswith('Group'):
                    # Parse the line - format is typically: ResidueNum Chain pKa model-pKa
                    parts = line.split()
                    if len(parts) >= 3:
                        # Check if this line contains our target residue
                        # The format might be like "ARG264 A" or "ARG 264"
                        first_part = parts[0]
                        second_part = parts[1] if len(parts) > 1 else ""
                        
                        # Handle different formats: "ARG264" vs "ARG 264"
                        if first_part.startswith(res_name) and second_part == chain_id:
                            # Format: "ARG264 A pKa"
                            res_name_num = first_part
                            found_res_name = ''
                            found_res_num = ''
                            for i, char in enumerate(res_name_num):
                                if char.isdigit():
                                    found_res_name = res_name_num[:i]
                                    found_res_num = res_name_num[i:]
                                    break
                            
                            if found_res_name == res_name and int(found_res_num) == res_num:
                                try:
                                    return float(parts[2])
                                except ValueError:
                                    continue
                        elif first_part == res_name and second_part.isdigit() and len(parts) > 2 and parts[2] == chain_id:
                            # Format: "ARG 264 A pKa"
                            if int(second_part) == res_num:
                                try:
                                    return float(parts[3])
                                except ValueError:
                                    continue
                        elif first_part == res_name and second_part.isdigit() and len(parts) > 1:
                            # Format: "ARG 264 pKa" (when chain is not present or at the end)
                            if int(second_part) == res_num:
                                try:
                                    if len(parts) > 2:
                                        return float(parts[2])
                                    else:
                                        continue
                                except ValueError:
                                    continue
                            
    except FileNotFoundError:
        print(f"Propka file {propka_file} not found")
        return None
    except Exception as e:
        print(f"Error reading propka file: {e}")
        return None
    
    return None

def extract_residue_type(protein_str):
    """Extract just the residue type: 'ARG', 'HIS', or 'LYS'."""
    match = re.match(r'([A-Z]+)-', str(protein_str))
    if match:
        res_code = match.group(1).upper()
        if res_code in {'ARG', 'HIS', 'LYS'}:
            return res_code
    return None

def process_csv_and_add_pka(input_csv, output_csv, pdb_pattern="*_only_protein.pdb", n_jobs=96):
    """
    Process the CSV file using multiple processes, run propka3 on each PDB file, 
    add pKa values as a new column, and save only rows with pKa > 7.4 to the output CSV.
    
    Args:
        input_csv: Path to input CSV file
        output_csv: Path to output CSV file with added pKa column (only pKa > 7.4)
        pdb_pattern: Pattern to match PDB files (default: "*_only_protein.pdb")
        n_jobs: Number of parallel jobs (default: 96)
    """
    # Get available CPUs
    available_cpus = mp.cpu_count()
    
    # Default to 96 jobs if at least 96 CPUs are available, otherwise use available CPUs
    if n_jobs == 96 and available_cpus < 96:
        print(f"Only {available_cpus} CPU(s) available, using {available_cpus} jobs instead of 96")
        n_jobs = available_cpus
    
    # Read the CSV file
    df = pd.read_csv(input_csv)
    
    # Create a new column for pKa values
    df['pKa'] = None
    
    # Prepare arguments for multiprocessing
    tasks = []
    for index, row in df.iterrows():
        directory = row['Directory']
        protein_info = row['Protein']
        
        # Find the PDB file in the directory
        original_dir = os.getcwd()
        try:
            os.chdir(directory)
            pdb_files = find_pdb_files('.', pdb_pattern)
            os.chdir(original_dir)
            
            if not pdb_files:
                print(f"No PDB files matching pattern '{pdb_pattern}' found in {directory}, skipping...")
                continue
            
            pdb_file = pdb_files[0]  # Use the first match
            print(f"Found PDB file: {pdb_file} in {directory}")
            
            tasks.append((directory, pdb_file, protein_info, pdb_pattern))
        except FileNotFoundError:
            print(f"Directory {directory} not found, skipping...")
            continue
        finally:
            os.chdir(original_dir)
    
    # Limit number of jobs to the number of tasks
    n_jobs = min(n_jobs, len(tasks))
    
    print(f"Processing {len(tasks)} tasks using {n_jobs} parallel jobs...")
    print(f"Available CPUs: {available_cpus}")
    
    # Process tasks in parallel
    with mp.Pool(processes=n_jobs) as pool:
        results = pool.map(run_propka_and_extract_pka, tasks)
    
    # Update the dataframe with results
    for directory, residue_info, pka_value in results:
        # Find the corresponding row in the dataframe
        mask = (df['Directory'] == directory) & (df['Protein'] == residue_info)
        indices = df[mask].index
        
        for idx in indices:
            df.at[idx, 'pKa'] = pka_value
            
            # Print status based on pKa value
            if pka_value is not None:
                if pka_value <= 7.4:
                    print(f"WARNING: Residue {residue_info} in {directory} has pKa = {pka_value:.2f} (<= 7.4) - Will be filtered out")
                else:
                    print(f"Residue {residue_info} in {directory} has pKa = {pka_value:.2f} (> 7.4) - Will be included")
            else:
                print(f"Could not determine pKa for {residue_info} in {directory}")
    
    # Filter the dataframe to include only rows with pKa > 7.4
    filtered_df = df[df['pKa'].notna() & (df['pKa'] > 7.4)]
    
    # Print summary of filtered results
    print(f"\nOriginal number of entries: {len(df)}")
    print(f"Entries with pKa > 7.4: {len(filtered_df)}")
    print(f"Entries filtered out (pKa <= 7.4): {len(df) - len(filtered_df)}")
    
    # Calculate and print filtered out statistics by residue type
    low_pka_entries = df[df['pKa'].notna() & (df['pKa'] <= 7.4)]
    
    if not low_pka_entries.empty:
        # Add residue type column
        low_pka_entries = low_pka_entries.copy()
        low_pka_entries['ResidueType'] = low_pka_entries['Protein'].apply(extract_residue_type)
        
        # Calculate counts and percentages for each residue type
        all_entries = df[df['pKa'].notna()].copy()
        all_entries['ResidueType'] = all_entries['Protein'].apply(extract_residue_type)
        
        for res_type in ['ARG', 'HIS', 'LYS']:
            total_res_type = len(all_entries[all_entries['ResidueType'] == res_type])
            filtered_out_res_type = len(low_pka_entries[low_pka_entries['ResidueType'] == res_type])
            
            if total_res_type > 0:
                percentage = (filtered_out_res_type / total_res_type) * 100
                print(f"{res_type} filtered out: {filtered_out_res_type}/{total_res_type} ({percentage:.2f}%)")
            else:
                print(f"{res_type} filtered out: 0/0 (0.00%)")
    else:
        print("ARG filtered out: 0/0 (0.00%)")
        print("HIS filtered out: 0/0 (0.00%)")
        print("LYS filtered out: 0/0 (0.00%)")
    
    # Save the filtered CSV (only entries with pKa > 7.4)
    filtered_df.to_csv(output_csv, index=False)
    print(f"\nFiltered output saved to {output_csv} with {len(filtered_df)} entries")

# Usage
input_csv = "reference_experimental_pication_interactions_report.csv"
output_csv = "reference_experimental_pication_interactions_report_with_pka_filtered.csv"



process_csv_and_add_pka(
    input_csv=input_csv, 
    output_csv=output_csv, 
    pdb_pattern="*_only_protein.pdb",  # Change this pattern as needed
    n_jobs=96  # Default to 96 jobs, but will adjust if fewer CPUs available
)
